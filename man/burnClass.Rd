% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/burnClass.R
\name{burnClassGenerator}
\alias{burnClassGenerator}
\alias{burnClassSummary}
\alias{burnClassPredict}
\alias{burnProbFromClass}
\title{Generate, Summarize, Predict Burn Classes from Covariates}
\usage{
burnClassGenerator(df, numClasses = 4:9, AUC = TRUE, plotAUC = FALSE)

burnClassSummary(mod)

burnClassPredict(mod, df)

burnProbFromClass(mod, df)
}
\arguments{
\item{df}{A \code{data.frame} (or \code{data.table}), with covariates, including "burned"
(a binary 0, 1; not burned = 0, burned = 1), e.g., \code{timeSinceFire}, \code{biomassJackPine},
etc. that will be used to find fuel classes.
This set of covariates must be available both during fitting and for prediction.
These must be quantitative.}

\item{numClasses}{A vector indicating how many classes should be attempted. The function
will return the number of classes that best classify the data into homogeneous groups.}

\item{AUC}{Logical. Should the Area Under the receiver operating Curve be returned?}

\item{plotAUC}{Logical. Should the plot of the AUC be made.}

\item{mod}{A model of class \code{Mclust}, e.g,. coming from \code{Mclust} or
\code{burnClassGenerator}}
}
\value{
A list with 2 elements, first the \code{model}, which comes from \code{mclust::Mclust},
and second the Area Under the Curve or AUC as an indicator of the overall goodness of fit.
}
\description{
Generate, Summarize, Predict Burn Classes from Covariates
}
\details{
This was inspired by reading here:
\url{https://www.datanovia.com/en/blog/types-of-clustering-methods-overview-and-quick-start-r-code/}
and here:
\url{https://www.datanovia.com/en/lessons/model-based-clustering-essentials/}, with
citation here:
Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering,
classification and density estimation using Gaussian finite mixture models,
The R Journal, 8/1, pp. 205-233.
\url{https://journal.r-project.org/archive/2016/RJ-2016-021/RJ-2016-021.pdf}
}
\section{The algorithm}{

The basic solution is to take all covariates, including the binary "not burned", "burned"
(coded as 0 and 1, respectively), and do model-based clustering with the \code{mclust}
R package. We can choose a fixed number of burn classes, or a finite range (see
\code{numClasses} argument.
This will make \code{numClasses} "homogeneous" groups,
including whether they burned or not.
From this, we can identify groups by looking at the mean values of "burned" to see
what their burn tendency is as a "homogeneous" group.
}

\section{Categorical data}{

For now, it is recommended to convert categorical data to dummy variables, 0 and 1.
E.g., For land cover, wetland class can be converted to a column "wetland" with
1 for data points that are wetlands and 0 for non-wetland.
}

\section{How much data to include}{

This has not been tested yet; however, I believe that having a relatively similar
number of "burned" and "unburned" pixels (within 3x either way), is probably a good idea.
In other words, if there are 100,000 burned data points, there should be between 30,000 and
300,000 unburned data points. If there are already buffers around the burned polygons that
include unburned pixels, then these buffers can be used as part of the unburned
content.
}

\examples{
\dontrun{
#################################
# Use own data; here is a generated set for reprex
library("data.table")
N <- 1e5
DT <- list()
for (i in c("train", "test")) {
  DT[[i]] <- data.table(burned = sample(c(0, 0, 0, 1), replace = TRUE, size = N))
  set(DT[[i]], NULL, "jp", rlnorm(N, mean = 4 + 0.5 * DT[[i]]$burned, sd = 0.25))
  set(DT[[i]], NULL, "bs", rlnorm(N, mean = 4 + 0.3 * DT[[i]]$burned, sd = 0.25))
  set(DT[[i]], NULL, "ws", rlnorm(N, mean = 4 + 0.2 * DT[[i]]$burned, sd = 0.25))
  set(DT[[i]], NULL, "age", rlnorm(N, mean = 4 - 0.2* DT[[i]]$burned, sd = 0.25))
  DT[[i]][, c("jp", "bs", "ws", "age") := lapply(.SD, function(x) x/max(x) * 1000),
            .SDcols = c("jp", "bs", "ws", "age")]
  DT[[i]][, c("age") := lapply(.SD, function(x) x/max(x) * 200), .SDcols = c("age")]
  summary(DT[[i]])
  boxplot(DT[[i]]$age ~ DT[[i]]$burned)
}

bc <- burnClassGenerator(DT[["train"]], 4:8)
# Show if the model is good at predicting burn state
(bc$AUC) # area under the curve

# print summary of mean values of each burn class
(summ <- burnClassSummary(bc$model))

# predict -- add Burn Class to object
set(DT[["test"]], NULL, "burnClass", burnClassPredict(bc$model, df = DT[["test"]]))
prob <- burnProbFromClass(bc$model, DT[["test"]])
}
}
\author{
Eliot McIntire
}
